# LLM Provider Selection
# Options: "anthropic" or "openai"
# Default: anthropic (if not set)
LLM_PROVIDER=anthropic

# ===== Anthropic Configuration (when LLM_PROVIDER=anthropic) =====
ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Optional: Specify Claude model (defaults to claude-sonnet-4-20250514)
CLAUDE_MODEL=claude-sonnet-4-20250514

# ===== OpenAI Configuration (when LLM_PROVIDER=openai) =====
OPENAI_API_KEY=your_openai_api_key_here
# Optional: Specify OpenAI base URL (defaults to https://api.openai.com/v1)
OPENAI_BASE_URL=https://api.openai.com/v1
# Optional: Specify OpenAI model (defaults to gpt-4-turbo-preview)
OPENAI_MODEL=gpt-4-turbo-preview

# ===== Example: Ollama Configuration (Local, Free) =====
# LLM_PROVIDER=openai
# OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_API_KEY=ollama
# OPENAI_MODEL=llama3.1

# ===== Example: Groq Configuration (Cloud, Free Tier) =====
# LLM_PROVIDER=openai
# OPENAI_BASE_URL=https://api.groq.com/openai/v1
# OPENAI_API_KEY=your_groq_api_key_here
# OPENAI_MODEL=llama-3.3-70b-versatile

# ===== Example: LM Studio Configuration (Local, Free) =====
# LLM_PROVIDER=openai
# OPENAI_BASE_URL=http://localhost:1234/v1
# OPENAI_API_KEY=lm-studio
# OPENAI_MODEL=your-local-model-name
